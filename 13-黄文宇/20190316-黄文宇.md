1、Java中的同步集合与并发集合有什么区别？

    Collections类提供了多个synchronizedXXX(方法)，该方法可以将指定集合包装成线程同步的集合，
 进而可以解决多线程并发访问集合时的线程安全问题 。
    Java中常用的集合框架中实现类hashSet、TreeSet、ArrayList、ArrayDeque、LinkedList、HashMap和TreeMap都是线程不安全的。
  如果有多个线程访问他们，而且有超过一个的线程试图修改他们，则存在线程安全的问题。Collections提供了多个类方法可以把他们
  包装成线程同步的集合。

public class SynchronizedThreadTest {
    public static void main (String[] args)
    {
        List list=Collections.synchronizedList(new ArrayList());

    }
}
并发提供的接口：
1、BlockingQueue ：阻塞式队列
    是对Queue<E> 接口的扩张
    
2、TransferQueue ： 事务队列，通过LinkedTransferQueue实现，
实现的方法有
    1）.tryTransfer(E)：将元素立刻给消费者。准确的说就是立刻给一个等待接收元素的线程，如果没有消费者就会返回false，而不将元素放入队列。
　　2）.transfer(E)：将元素给消费者，如果没有消费者就会等待。
　　3）.tryTransfer(E,long,TimeUnit)：将元素立刻给消费者，如果没有就等待指定时间。给失败返回false。
　　4）.hasWaitingConsumer()：返回当前是否有消费者在等待元素。
　　5）.getWaitingConsumerCount()：返回等待元素的消费者个数。

3、BlockingDeque  ：
表示一个双端队列。该双端队列，线程可以安全的插入，和取出元素。线程插入或者移出队列中的元素时，可能会阻塞。
通过LinkedBlockingDeque实现

BlockingDequedeque = new LinkedBlockingDeque();
deque.addFirst("1");
deque.addLast("2");
String two = deque.takeLast();
String one = deque.takeFirst();

4、ConcurrentMap：并发的HashMap通过ConcurrentHashMap, ConcurrentSkipListMap这两个类实现
ConcurrentMap的实现类主要以ConcurrentHashMap为主
在Map的基础上提供了以下四种方法（since 1.8）
    //插入元素
    V putIfAbsent(K key, V value);
    //移除元素
    boolean remove(Object key, Object value);
    //替换元素
    boolean replace(K key, V oldValue, V newValue);
    //替换元素
    V replace(K key, V value);

5、ConcurrentNavigableMap  可导航的高并发map
    基于ConcurrentMap<K,V>, Map<K,V>, NavigableMap<K,V>, SortedMap<K,V>接口的扩展
    通过ConcurrentSkipListMap类实现。
    比较经常用的方法：descendingKeySet()、 descendingMap()、   navigableKeySet()
    
并发的提供的实现类：
1、LinkedBlockingQueue：链表阻塞式队列
 主要是创建队列，入队、出队。
入队的比较：
1）、offer(E e)：如果队列没满，立即返回true； 如果队列满了，立即返回false-->不阻塞
2）、put(E e)：如果队列满了，一直阻塞，直到队列不满了或者线程被中断-->阻塞
3）、offer(E e, long timeout, TimeUnit unit)：在队尾插入一个元素,，如果队列已满，则进入等待，直到出现以下三种情况：-->阻塞
  ：被唤醒
  ：等待时间超时
  ：当前线程被中断
  
出队比较：
  
  1）、poll()：如果没有元素，直接返回null；如果有元素，出队
  2）、take()：如果队列空了，一直阻塞，直到队列不为空或者线程被中断-->阻塞
  3）、poll(long timeout, TimeUnit unit)：如果队列不空，出队；如果队列已空且已经超时，返回null；如果队列已空且时间未超时，则进入等待，直到出现以下三种情况：
      ：被唤醒
      ：等待时间超时
      ：当前线程被中断

2、ArrayBlockingQueue
   由数组结构组成的有界阻塞队
   提供的构造方法：
   public ArrayBlockingQueue(int capacity) ：构造指定大小的有界队列 
   public ArrayBlockingQueue(int capacity, boolean fair) ：构造指定大小的有界队列，指定为公平或非公平锁 
   public ArrayBlockingQueue(int capacity, boolean fair, Collection<? extends E> c)  构造指定大小的有界队列，指定为公平或非公平锁，指定在初始化时加入一个集合 
    ArrayBlockingQueue 使用可重入锁 ReentrantLock 控制队列的访问，两个 Condition 实现生产者-消费者模型
    见源码提供的：public E poll(long timeout, TimeUnit unit) throws InterruptedException ;
    public E peek() {
        final ReentrantLock lock = this.lock;
        lock.lock();
        try {
            return itemAt(takeIndex); // null when queue is empty
        } finally {
            lock.unlock();
        }
    }
    final E itemAt(int i) {
        return (E) items[i];
    }


注：ArrayBlockingQueue与LinkedBlockingQueue对比  
  1）、ArrayBlockingQueue：
     一个对象数组+一把锁+两个条件
    入队与出队都用同一把锁
    在只有入队高并发或出队高并发的情况下，因为操作数组，且不需要扩容，性能很高
    采用了数组，必须指定大小，即容量有限
  2）、LinkedBlockingQueue：
    一个单向链表+两把锁+两个条件
    两把锁，一把用于入队，一把用于出队，有效的避免了入队与出队时使用一把锁带来的竞争。
    在入队与出队都高并发的情况下，性能比ArrayBlockingQueue高很多
    采用了链表，最大容量为整数最大值，可看做容量无限
    
    
3、PriorityBlockingQueue
支持优先级排序的无界阻塞队列
1）、PriorityBlockingQueue是带优先级的无界阻塞队列，每次出队都返回优先级最高的元素，是二叉树最小堆的实现，研究过数组方式存放最小堆节点的都知道，直接遍历队列元素是无序的。
2）在类的方法allocationSpinLockOffset是用来在扩容队列时候做cas的，目的是保证只有一个线程可以进行扩容。
   这是一个优先级队列所以有个比较器comparator用来比较元素大小。lock独占锁对象用来控制同时只能有一个线程可以进行入队出队操作。
   notEmpty条件变量用来实现take方法阻塞模式。这里没有notFull 条件变量是因为这里的put操作是非阻塞的，为啥要设计为非阻塞的是因为这是无界队列。
具体见源码：private static final int DEFAULT_INITIAL_CAPACITY = 11;    
       public PriorityBlockingQueue() {
              this(DEFAULT_INITIAL_CAPACITY, null);
          }     
          public PriorityBlockingQueue(int initialCapacity) {
              this(initialCapacity, null);
          }      
          public PriorityBlockingQueue(int initialCapacity,
                                       Comparator<? super E> comparator) {
              if (initialCapacity < 1)
                  throw new IllegalArgumentException();
              this.lock = new ReentrantLock();
              this.notEmpty = lock.newCondition();
              this.comparator = comparator;
              this.queue = new Object[initialCapacity];
          }
        }
 4）、扩容的方法源代码如下:
   private void tryGrow(Object[] array, int oldCap) {
       lock.unlock(); //must release and then re-acquire main lock
       Object[] newArray = null;    
       //cas成功则扩容(4)
       if (allocationSpinLock == 0 &&
           UNSAFE.compareAndSwapInt(this, allocationSpinLockOffset,
                                    0, 1)) {
           try {
               //oldGap<64则扩容新增oldcap+2,否者扩容50%，并且最大为MAX_ARRAY_SIZE
               int newCap = oldCap + ((oldCap < 64) ?
                                      (oldCap + 2) : // grow faster if small
                                      (oldCap >> 1));
               if (newCap - MAX_ARRAY_SIZE > 0) {    // possible overflow
                   int minCap = oldCap + 1;
                   if (minCap < 0 || minCap > MAX_ARRAY_SIZE)
                       throw new OutOfMemoryError();
                   newCap = MAX_ARRAY_SIZE;
               }
               if (newCap > oldCap && queue == array)
                   newArray = new Object[newCap];
           } finally {
               allocationSpinLock = 0;
           }
       }  
       //第一个线程cas成功后，第二个线程会进入这个地方，然后第二个线程让出cpu，尽量让第一个线程执行下面点获取锁，但是这得不到肯定的保证。(5)
       if (newArray == null) // back off if another thread is allocating
           Thread.yield();
       lock.lock();(6)
       if (newArray != null && queue == array) {
           queue = newArray;
           System.arraycopy(array, 0, newArray, 0, oldCap);
       }
   }         
        tryGrow目的是扩容，这里要思考下为啥在扩容前要先释放锁，然后使用cas控制只有一个线程可以扩容成功。我的理解是为了性能，
    因为扩容时候是需要花时间的，如果这些操作时候还占用锁那么其他线程在这个时候是不能进行出队操作的，也不能进行入队操作，
    这大大降低了并发性。
    
        所以在扩容前释放锁，这允许其他出队线程可以进行出队操作，但是由于释放了锁，所以也允许在扩容时候进行入队操作，
    这就会导致多个线程进行扩容会出现问题，所以这里使用了一个spinlock用cas控制只有一个线程可以进行扩容，
    失败的线程调用Thread.yield()让出cpu，目的意在让扩容线程扩容后优先调用lock.lock重新获取锁，但是这得不到一定的保证，
    有可能调用Thread.yield()的线程先获取了锁。
    
         那copy元素数据到新数组为啥放到获取锁后面那?原因应该是因为可见性问题，因为queue并没有被volatile修饰。
    另外有可能在扩容时候进行了出队操作，如果直接拷贝可能看到的数组元素不是最新的。而通过调用Lock后，获取的数组则是最新的，
    并且在释放锁前 数组内容不会变化。 
    说明：     
    PriorityBlockingQueue类似于ArrayBlockingQueue内部使用一个独占锁来控制同时只有一个线程可以进行入队和出队，
    另外前者只使用了一个notEmpty条件变量而没有notFull这是因为前者是无界队列，当put时候永远不会处于await所以也不需要被唤醒。
    
    PriorityBlockingQueue始终保证出队的元素是优先级最高的元素，并且可以定制优先级的规则，内部通过使用一个二叉树最
    小堆算法来维护内部数组，这个数组是可扩容的，当当前元素个数>=最大容量时候会通过算法扩容。
    
    值得注意的是为了避免在扩容操作时候其他线程不能进行出队操作，实现上使用了先释放锁，然后通过cas保证同时只有一个线程可以
    扩容成功。
    
    
4、DelayQueue
使用优先级队列实现的无界阻塞队列
    是一个支持延时获取元素的无界阻塞队列。队列内部使用PriorityQueue来实现。在创建元素时可以指定多久才能从队列中获取当前元素。
只有在延迟期满时才能从队列中提取元素，如果元素没有达到延时时间，就阻塞当前线程。
    getDelay（TimeUnit.NANOSECONDS）方法返回小于或等于零的值时，会发生到期。即使使用take或poll无法删除未到期的元素，
    例如，size方法返回已过期和未过期元素的计数。
    
 说明（使用场景）：
 缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询
 DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。
 
 定时任务调度：使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，
 比如TimerQueue就是使用DelayQueue实现的。



5、SynchronousQueue
不存储元素的阻塞队列
提供的方法：
      1）、iterator() 永远返回空，因为里面没东西。 
      2）、 peek() 永远返回null。 
      3）、 put() 往queue放进去一个element以后就一直wait直到有其他thread进来把这个element取走。 
      4）、 offer() 往queue里放一个element后立即返回，如果碰巧这个element被另一个thread取走了，offer方法返回true，认为offer成功；否则返回false。 
      5）、 offer(2000, TimeUnit.SECONDS) 往queue里放一个element但是等待指定的时间后才返回，返回的逻辑和offer()方法一样。 
      6）、 take() 取出并且remove掉queue里的element（认为是在queue里的。。。），取不到东西他会一直等。 
      7）、 poll() 取出并且remove掉queue里的element（认为是在queue里的。。。），只有到碰巧另外一个线程正在往queue里offer数据或者put数据的时候，该方法才会取到东西。否则立即返回null。 
      8）、 poll(2000, TimeUnit.SECONDS) 等待指定的时间然后取出并且remove掉queue里的element,其实就是再等其他的thread来往里塞。 
      9）、 isEmpty()永远是true。 
      10）、 remainingCapacity() 永远是0。 
      11）、remove()和removeAll() 永远是false。
            SynchronousQueue 内部没有容量，但是由于一个插入操作总是对应一个移除操作，反过来同样需要满足。
           那么一个元素就不会再SynchronousQueue 里面长时间停留，一旦有了插入线程和移除线程，元素很快就从插入线程移交给移除线程。
      也就是说这更像是一种信道（管道），资源从一个方向快速传递到另一方 向。显然这是一种快速传递元素的方式，也就是说在这种
      情况下元素总是以最快的方式从插入着（生产者）传递给移除着（消费者），这在多任务队列中是最快处理任务的方式。在线程池里
      的一个典型应用是Executors.newCachedThreadPo
      ol()就使用了SynchronousQueue，这个线程池根据需要（新任务到来时）创建新的
      线程，如果有空闲线程则会重复使用，线程空闲了60秒后会被回收
      
   说明：   
      SynchronousQueue由于其独有的线程一一配对通信机制，在大部分平常开发中，可能都不太会用到，
      但线程池技术中会有所使用，由于内部没有使用AQS，而是直接使用CAS，所以代码理解起来会比较困难

6、LinkedBlockingQueue和LinkedBlockingDeque
 由链表结构组成的双向阻塞队列
 LinkedBlockingQueue：一端入
 LinkedBlockingDeque：两端入
  特点：
    链表结构（动态数组）
    通过ReentrantLock实现锁
    利用Condition实现队列的阻塞等待，唤醒
  LinkedBlockingQueue：只能一端出一端如的单向队列结构，是有FIFO特性的，并且是通过两个ReentrantLock和两个Condition来实现
  LinkedBlockingQueue：LinkedBlockingQueue采用了两把锁来对队列进行操作，也就是队尾添加的时候， 队头仍然可以删除等操作
  具体见源代码：
   public void put(E e) throws InterruptedException {
          if (e == null) throw new NullPointerException();   //e不能为null
          int c = -1;
          Node<E> node = new Node<E>(e);
          final ReentrantLock putLock = this.putLock;     //获取put锁
          final AtomicInteger count = this.count;          //获取count
          putLock.lockInterruptibly();
          try {
              while (count.get() == capacity) {        //如果满了，那么就需要使用notFull阻塞
                  notFull.await();
              }
              enqueue(node);
              c = count.getAndIncrement();
              if (c + 1 < capacity)                    //如果此时又有空间了，那么notFull唤醒
                  notFull.signal();
          } finally {
              putLock.unlock();             //释放锁
          }
          if (c == 0)            //当c为0时候，也要根take锁说一下，并发下
              signalNotEmpty();        //调用notEmpty        
      }
      //队尾操作
        private void enqueue(Node<E> node) {        //入对操作。
         last = last.next = node;      //队尾进
     }
     具体见源代码
  。。。。。。
  
7、LinkedTransferQueue
由链表结构组成的无界阻塞队列，基于TransferQueue<E>, Serializable的实现
    LinkedTransferQueue采用一种预占模式。意思就是消费者线程取元素时，如果队列不为空，则直接取走数据，
 若队列为空，那就生成一个节点（节点元素为null）入队，然后消费者线程被等待在这个节点上，后面生产者线程入队时
 发现有一个元素为null的节点，生产者线程就不入队了，直接就将元素填充到该节点，并唤醒该节点等待的线程，被唤醒
 的消费者线程取走元素，从调用的方法返回。我们称这种节点操作为“匹配”方式。

    LinkedTransferQueue类继承自AbstractQueue抽象类，并且实现了TransferQueue接口
    见代码:public interface TransferQueue<E> extends BlockingQueue<E> {
            // 如果存在一个消费者已经等待接收它，则立即传送指定的元素，否则返回false，并且不进入队列。
            boolean tryTransfer(E e);
            // 如果存在一个消费者已经等待接收它，则立即传送指定的元素，否则等待直到元素被消费者接收。
            void transfer(E e) throws InterruptedException;
            // 在上述方法的基础上设置超时时间
            boolean tryTransfer(E e, long timeout, TimeUnit unit)
                throws InterruptedException;
            // 如果至少有一位消费者在等待，则返回true
            boolean hasWaitingConsumer();
            // 获取所有等待获取元素的消费线程数量
            int getWaitingConsumerCount();
     }
     
     *****实现LinkedTransferQueue的关键方法xfer方法
     private E xfer(E e, boolean haveData, int how, long nanos) {
         // 如果haveData但是e为null，则抛出NullPointerException异常
         if (haveData && (e == null))
             throw new NullPointerException();
         // s是将要被添加的节点，如果需要
         Node s = null;                        // the node to append, if needed
      
         retry:
         for (;;) {                            // restart on append race
             // 从首节点开始匹配
             for (Node h = head, p = h; p != null;) { // find & match first node
                 boolean isData = p.isData;
                 Object item = p.item;
                 // 判断节点是否被匹配过
                  item != null有2种情况：一是put操作，二是take的item被修改了(匹配成功)
                 (itme != null) == isData 要么表示p是一个put操作，要么表示p是一个还没匹配成功的take操作
                 if (item != p && (item != null) == isData) { // unmatched
                     // 节点与此次操作模式一致，无法匹配
                     if (isData == haveData)   // can't match
                         break;
                     // 匹配成功
                     if (p.casItem(item, e)) { // match
                         for (Node q = p; q != h;) {
                             Node n = q.next;  // update by 2 unless singleton
                             // 更新head为匹配节点的next节点
                             if (head == h && casHead(h, n == null ? q : n)) {
                                 // 将旧节点自连接
                                 h.forgetNext();
                                 break;
                             }                 // advance and retry
                             if ((h = head)   == null ||
                                 (q = h.next) == null || !q.isMatched())
                                 break;        // unless slack < 2
                         }
                         // 匹配成功，则唤醒阻塞的线程
                         LockSupport.unpark(p.waiter);
                         // 类型转换，返回匹配节点的元素
                         return LinkedTransferQueue.<E>cast(item);
                     }
                 }
                 // 若节点已经被匹配过了，则向后寻找下一个未被匹配的节点
                 Node n = p.next;
                 // 如果当前节点已经离队，则从head开始寻找
                 p = (p != n) ? n : (h = head); // Use head if p offlist
             }
      
             // 若整个队列都遍历之后，还没有找到匹配的节点，则进行后续处理
             // 把当前节点加入到队列尾
             if (how != NOW) {                 // No matches available
                 if (s == null)
                     s = new Node(e, haveData);
                 // 将新节点s添加到队列尾并返回s的前驱节点
                 Node pred = tryAppend(s, haveData);
                 // 前驱节点为null，说明有其他线程竞争，并修改了队列，则从retry重新开始
                 if (pred == null)
                     continue retry;           // lost race vs opposite mode
                 // 不为ASYNC方法，则同步阻塞等待
                 if (how != ASYNC)
                     return awaitMatch(s, pred, e, (how == TIMED), nanos);
             }
             // how == NOW，则立即返回
             return e; // not waiting
         }
  }   
    通过CAS操作更新head节点为匹配节点的next节点，旧head节点进行自连接，唤醒匹配节点的等待线程waiter，
    返回匹配的 item。如果CAS失败，并且松弛度大于等于2，就需要重新获取head重试。
    
    在节点被匹配（被删除）之后，不会立即更新head/tail，而是当 head/tail 节点和最近一个未匹配的节点之间距
    离超过一个“松弛阀值”之后才会更新（在LinkedTransferQueue中，这个值为 2）。这个“松弛阀值”一般为1-3，
    如果太大会降低缓存命中率，并且会增加遍历链的长度；太小会增加 CAS 的开销。


8、CopyOnWriteArrayList
   写时复制的容器
    当我们往一个容器添加元素的时候，不直接往当前容器添加，而是先将当前容器进行Copy，复制出一个新的容器，
    然后新的容器里添加元素，添加完元素之后，再将原容器的引用指向新的容器。这样做的好处是我们可以
    对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。所以CopyOnWrite容器也
    是一种读写分离的思想，读和写不同的容器。
    具体代码
    Object[] newElements = Arrays.copyOf(elements, len + 1);
            newElements[len] = e;
            setArray(newElements);
            
   说明：opyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，
   但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单当中，黑名单每天晚上更新一次。当用户搜索时，会检查当前关键字在不在黑名单当中，如果在，则提示不能搜索。         
             
   使用的优缺点：
   CopyOnWrite容器有很多优点，但是同时也存在两个问题，即内存占用问题和数据一致性问题。所以在开发的时候需要注意一下。
   
   　　** 内存占用问题。因为CopyOnWrite的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的
   内存，旧的对象和新写入的对象（注意:在复制的时候只是复制容器里的引用，只是在写的时候会创建新对象添加到新
   容器里，而旧容器的对象还在使用，所以有两份对象内存）。如果这些对象占用的内存比较大，比如说200M左右，那
   么再写入100M数据进去，内存就会占用300M，那么这个时候很有可能造成频繁的Yong GC和Full GC。之前我们系统中
   使用了一个服务由于每晚使用CopyOnWrite机制更新大对象，造成了每晚15秒的Full GC，应用响应时间也随之变长。
   
   　　** 针对内存占用问题，可以通过压缩容器中的元素的方法来减少大对象的内存消耗，比如，如果元素全是10进制
   的数字，可以考虑把它压缩成36进制或64进制。或者不使用CopyOnWrite容器，而使用其他的并发容器，如ConcurrentHashMap。
   
   　　** 数据一致性问题。CopyOnWrite容器只能保证数据的最终一致性，不能保证数据的实时一致性。所以
   如果你希望写入的的数据，马上能读到，请不要使用CopyOnWrite容器。
   
9、CopyOnWriteArraySet

    它是线程安全的无序的集合，可以将它理解成线程安全的HashSet，CopyOnWriteArraySet和HashSet虽
    然都继承于共同的父类AbstractSet；但是，HashSet是通过“散列表(HashMap)”实现的，而CopyOnWriteArraySet则
    是通过“动态数组(CopyOnWriteArrayList)”实现的，并不是散列表。
        特性：
        1. 它最适合于具有以下特征的应用程序：Set 大小通常保持很小，只读操作远多于可变操作，需要在遍历期间防止线程间的冲突。
        2. 它是线程安全的。
        3. 因为通常需要复制整个基础数组，所以可变操作（add()、set() 和 remove() 等等）的开销很大。
        4. 迭代器支持hasNext(), next()等不可变操作，但不支持可变 remove()等 操作。
        5. 使用迭代器进行遍历的速度很快，并且不会与其他线程发生冲突。在构造迭代器时，迭代器依赖于不变的数组快照。
      CopyOnWriteArraySet主要方法
       public boolean add(E e);
       public boolean remove(Object o);
       
ConcurrentSkipListSet<E>在jdk的API的文档说明： 
        1）ConcurrentSkipListSet<E>是jdk6新增的类，位于java.util.concurrent并发库下；  
           2）ConcurrentSkipListSet<E>和TreeSet一样，都是支持自然排序，并且可以在构造的时候定义Comparator<E>的比较器，该类的方法基本和TreeSet中方法一样（方法签名一样）； 
           3）和其他的Set集合一样，ConcurrentSkipListSet<E>都是基于Map集合的，ConcurrentSkipListMap便是它的底层实现； 
           4）在多线程的环境下，ConcurrentSkipListSet<E>中的contains、add、remove操作是安全的，多个线程可以安全地并发 

10、ConcurrentSkipListSet
  线程安全的有序的集合
  1) ConcurrentSkipListSet继承于AbstractSet。因此，它本质上是一个集合。
  2) ConcurrentSkipListSet实现了NavigableSet接口。因此，ConcurrentSkipListSet是一个有序的集合。
  3) ConcurrentSkipListSet是通过ConcurrentSkipListMap实现的。它包含一个ConcurrentNavigableMap对象m，
    而m对象实际上是ConcurrentNavigableMap的实现类ConcurrentSkipListMap的实例。ConcurrentSkipListMap中
    的元素是key-value键值对；而ConcurrentSkipListSet是集合，它只用到了ConcurrentSkipListMap中的key。
  
  是基于链表的，在链表的基础上加了多层索引结构，查找性能与二叉树类似，复杂度是O(log(N))
  ConcurrentSkipListSet也是基于ConcurrentSkipListMap实现。
  
  
11、ConcurrentHashMap
        多线程环境下，使用Hashmap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap
        不安全就因此诞生了ConcurrentHashMap。
            ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问
        其中一个段数据的时候，其他段的数据也能被其他线程访问。有些方法需要跨段，比如size()和containsValue()，它们可能需要
        锁定整个表而而不仅仅是某个段，这需要按顺序锁定所有段，操作完毕后，又按顺序释放所有段的锁。这里“按顺序”是很重要的，
        否则极有可能出现死锁，在ConcurrentHashMap内部，段数组是final的，并且其成员变量实际上也是final的，但是，仅仅是将数组
        声明为final的并不保证数组成员也是final的，这需要实现上的保证。这可以确保不会出现死锁，因为获得锁的顺序是固定的。
            ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，
         在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，
         Segment的结构和HashMap类似，是一种数组和链表结构， 一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结
         构的元素， 每个Segment守护者一个HashEntry数组里的元素,当对HashEntry数组的数据进行修改时，必须首先获得它对
         应的Segment锁。
        HashEntry的源代码
            static final class HashEntry<K,V> {  
                 final K key;  
                 final int hash;  
                 volatile V value;  
                 final HashEntry<K,V> next;  
             } 

            JDK1.8版本的CurrentHashMap的实现原理
            JDK8中ConcurrentHashMap参考了JDK8 HashMap的实现，采用了数组+链表+红黑树的实现方式来设计，内部大量采用CAS操作，这里我简要介绍下CAS。            
            CAS是compare and swap的缩写，即我们所说的比较交换。cas是一种基于锁的操作，而且是乐观锁。在java中锁分为乐观锁和悲观锁。悲观锁是将资源锁住，
            等一个之前获得锁的线程释放锁之后，下一个线程才可以访问。而乐观锁采取了一种宽泛的态度，通过某种方式不加锁来处理资源，比如通过给记录加version来获取数据，
            性能较悲观锁有很大的提高。
            
            CAS 操作包含三个操作数 —— 内存位置（V）、预期原值（A）和新值(B)。如果内存地址里面的值和A的值是一样的，那么就将内存里面的值更新成B。
            CAS是通过无限循环来获取数据的，若果在第一轮循环中，a线程获取地址里面的值被b线程修改了，那么a线程需要自旋，到下次循环才有可能机会执行。    
            JDK8中彻底放弃了Segment转而采用的是Node，其设计思想也不再是JDK1.7中的分段锁思想。                      
            Node：保存key，value及key的hash值的数据结构。其中value和next都用volatile修饰，保证并发的可见性。
             classNode<K,V>implementsMap.Entry<K,V>{finalint hash;final K key;volatile V val;volatileNode<K,V> next;//... 省略部分代码}</strong> 
            Java8 ConcurrentHashMap结构基本上和Java8的HashMap一样，不过保证线程安全性。
                在JDK8中ConcurrentHashMap的结构，由于引入了红黑树，使得ConcurrentHashMap的实现非常复杂，我们都知道，红黑树是
            一种性能非常好的二叉查找树，其查找性能为O（logN），但是其实现过程也非常复杂，而且可读性也非常差，DougLea的思维能力
            确实不是一般人能比的，早期完全采用链表结构时Map的查找时间复杂度为O（N），JDK8中ConcurrentHashMap在链表的长度大于某个
            阈值的时候会将链表转换成红黑树进一步提高其查找性能。
    

12、ConcurrentSkipListMap
      ConcurrentSkipListMap的底层是通过跳表来实现的。跳表是一个链表，但是通过使用“跳跃式”
      查找的方式使得插入、读取数据时复杂度变成了O（logn）。
      
            跳表（SkipList）：使用“空间换时间”的算法，令链表的每个结点不仅记录next结点位置，还可以按照level层
      级分别记录后继第level个结点。在查找时，首先按照层级查找，比如：当前跳表最高层级为3，即每个结点中不
      仅记录了next结点（层级1），还记录了next的next（层级2）、next的next的next（层级3）结点。现在查找一
      个结点，则从头结点开始先按高层级开始查：head->head的next的next的next->XX直到找到结点或者当前结
      点q的值大于所查结点，则此时当前查找层级的q的前一节点p开始，在p~q之间进行下一层级（隔1个结点）的查找.....
      .直到最终迫近、找到结点。此法使用的就是“先大步查找确定范围，再逐渐缩小迫近”的思想进行的查找。
      
         ConcurrentSkipListMap线程安全的原理与非阻塞队列ConcurrentBlockingQueue的原理一样：
      利用底层的插入、删除的CAS原子性操作，通过死循环不断获取最新的结点指针来保证不会出现竞态条件。
          ConcurrentHashMap采取了“锁分段”技术来细化锁的粒度：把整个map划分为一系列被成为segment的组成单
       元，一个segment相当于一个小的hashtable。这样，加锁的对象就从整个map变成了一个更小的范围。
       一个segment。ConcurrentHashMap线程安全并且提高性能原因就在于：对map中的读是并发的，无需加锁；只有
       在put、remove操作时才加锁，而加锁仅是对需要操作的segment加锁，不会影响其他segment的读写，由此，
       不同的segment之间可以并发使用，极大地提高了性能。
       
       
       
        Segment的结构
         static final class Segment<K,V> extends ReentrantLock implements Serializable {
             transient volatile int count;
             transient int modCount;
             transient int threshold;
             transient volatile HashEntry<K,V>[] table;
             final float loadFactor;
         }
         说明：
            ConcurrentHashMap在统计size时，经历了两次遍历：第一次不加锁地遍历所以segment，统计count和
          modCount的总和得到C1和M1；然后再次不加锁地遍历，得到C2和M2，比较M1和M2，如果修改次数没有发生变化
          则说明两次遍历期间map没有发生数量变化，那么C1就是可用的。如果M1不等于M2，则说明在统计过程中map的
          数量发生了变化，此时才采取最终手段——锁住整个map进行统计。
         
   
   
   

2、Java中invokeAndWait 和 invokeLater有什么区别？ 
     Swing是单线程，
     1）、主线程
     2）、系统工具包线程:负责捕获操作系统事件，然后将事件转换成swing的事件，然后发送到事件派发线程EDT
     3）、事件派发线程(EDT):将事件派发到各个组件，并负责调用绘制方法更新界面
     
     所有的事件，例如键盘，鼠标事件，都会由工具包线程转换成swing事件，然后放到事件队列EventQueue中，而这个EventQueue的派发机制是由EDT来管理的
      
     都是SwingUtilities类中提供的方法，
     1）、invokeLater和invokeAndWait都是将run方法中的代码交给同一个线程（即EDT，事件分发线程）去处理，按照顺序排队执行。    
     2）、invokeLater方法，将run方法交给EDT后，接着直接返回（不关注是否执行了），main方法继续执行。    
     3）、invokeAndWait方法，将run方法交给EDT后，会等待run方法执行完，main方法才继续向下执行。 invokeLater是AWT线程的一个异步事件。 
     Java中invokeAndWait是AWT线程的一个同步事件
     
     
3、什么是FutureTask？
         FutureTask包装器是一种非常便利的机制，同时实现了Future和Runnable接口。            
         Future保存异步计算的结果。可以启动一个计算，将Future对象交给某个线程，然后忘掉它。Future对象的所有者在结果计算好之后就可以获得它。
         Future接口具有下面的方法：
            public interface Future<V> {
                boolean cancel(boolean mayInterruptIfRunning);
                boolean isCancelled();
                boolean isDone();
                V get() throws InterruptedException, ExecutionException;
                V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;
            }
         1）、FutureTask的执行过程
                创建一个futureTask对象task
                提交task到调度器executor等待调度或者在另外一个线程中执行task            
                等待调度中...           
                如果此时currentThread调取执行结果task.get(),会有几种情况
                if task 还没有被executor调度或正在执行中
                    阻塞当前线程，并加入到一个阻塞链表中waitNode
                else if task被其它Thread取消，并取消成功 或task处于中断状态
                    throw exception
                else if task执行完毕，返回执行结果，或执行存在异常，返回异常信息
                
          2）、应用场景
             2.1）. Future用于异步获取执行结果或者取消任务。
             2.2）. 在高并发场景下确保任务只执行一次
            
            
            